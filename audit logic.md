Below is a **minimal, clean extension** to your existing design that adds
‚úÖ **batch_id in stage**
‚úÖ **record-count audits**
without changing the overall flow.

---

## 1Ô∏è‚É£ Why batch_id only in STG (quick rationale)

* Stage is **operational** ‚Üí batch tracking needed
* Main is **business-curated** ‚Üí batch_id usually not required
* Keeps main table clean and stable

---

## 2Ô∏è‚É£ Changes to STG Table

```sql
ALTER TABLE stg.fin_trans_fact
ADD COLUMNS (
  batch_id STRING,
  load_ts TIMESTAMP
);
```

---

## 3Ô∏è‚É£ Audit Table (STG)

```sql
CREATE TABLE IF NOT EXISTS stg.fin_trans_fact_audit (
  batch_id STRING,
  source_count BIGINT,
  stage_count BIGINT,
  main_merge_count BIGINT,
  status STRING,
  audit_ts TIMESTAMP
)
USING DELTA;
```

---

## 4Ô∏è‚É£ Generate batch_id (PySpark ‚Äì orchestration only)

```python
from datetime import datetime

batch_id = datetime.now().strftime("%Y%m%d%H%M%S")
```

---

## 5Ô∏è‚É£ Add batch_id to Incremental Data (DF ‚Üí Temp View)

```python
from pyspark.sql.functions import lit, current_timestamp

oracle_df_with_batch = (
    oracle_df
    .withColumn("batch_id", lit(batch_id))
    .withColumn("load_ts", current_timestamp())
)

oracle_df_with_batch.createOrReplaceTempView("fin_trans_fact_inc")
```

---

## 6Ô∏è‚É£ Load to STG (SQL file stays the same)

```sql
INSERT INTO stg.fin_trans_fact
SELECT *
FROM fin_trans_fact_inc;
```

---

## 7Ô∏è‚É£ Record-Count Audits

### Source Count (Oracle DF)

```python
source_count = oracle_df.count()
```

---

### Stage Count (SQL)

```python
stage_count = (
    spark.sql(f"""
      SELECT COUNT(*)
      FROM stg.fin_trans_fact
      WHERE batch_id = '{batch_id}'
    """)
    .collect()[0][0]
)
```

---

### Merge Count (affected rows)

```python
main_merge_count = (
    spark.sql("""
      SELECT COUNT(*)
      FROM fin_trans_fact_enriched
    """)
    .collect()[0][0]
)
```

---

## 8Ô∏è‚É£ Insert Audit Record

```python
spark.sql(f"""
  INSERT INTO stg.fin_trans_fact_audit
  VALUES (
    '{batch_id}',
    {source_count},
    {stage_count},
    {main_merge_count},
    'SUCCESS',
    current_timestamp()
  )
""")
```

---

## 9Ô∏è‚É£ Updated Flow (with batch & audit)

```
Oracle.fin_trans_fact
        ‚Üì (incremental)
stg.fin_trans_fact (batch_id, load_ts)
        ‚Üì
audit counts captured
        ‚Üì
transform + merge
        ‚Üì
main.fin_trans_fact
        ‚Üì
audit logged
```

---

## 10Ô∏è‚É£ What This Gives You (Short)

* üîÅ Safe reruns (`DELETE WHERE batch_id = ?`)
* üìä Source ‚Üî Stage ‚Üî Main reconciliation
* üß™ Easy failure analysis
* üõ† Production-grade observability

---

If you want next:

* **Auto-rollback on count mismatch**
* **Duplicate prevention using batch_id**
* **Databricks Workflow integration**

Just say üëç
